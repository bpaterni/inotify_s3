#!/bin/bash
#
# Push2 S3
# Copyright (c) 2013-2014 Alexey Baikov <sysboss [at] mail.ru>
#
# Watches specified directory for changes and copy newly created
# or modified files to Amazon S3 Cloud.
#
# 2020.06.28 - Augment the script to pull AWS access credentials from vault.
#
# TODO: cache credentials in some way to avoid pulling fresh on every call

#WATCH_DIR='/some/dir'
#PID_FILE='/var/run/push2s3.pid'
#BUCKET='amazon_bucket_name'

: "${PUSH2S3_WATCH_DIR:?Environment variable PUSH2S3_WATCH_DIR is not set}"
: "${PUSH2S3_BUCKET:?Environment variable PUSH2S3_BUCKET is not set}"
: "${VAULT_ROLE_LOGIN_PATH:?Environment variable VAULT_ROLE_LOGIN_PATH is not set}"
: "${VAULT_ROLE_ID:?Environment variable VAULT_ROLE_ID is not set}"
: "${VAULT_ROLE_SECRET_ID:?Environment variable VAULT_ROLE_SECRET_ID is not set}"
: "${VAULT_KV_ACCESS_TOKEN_PATH:?Environment variable VAULT_KV_ACCESS_TOKEN_PATH is not set}"

if [ ! -d "$PUSH2S3_WATCH_DIR" ]; then
  echo "ERROR: Directory '${PUSH2S3_WATCH_DIR}' does not exist!"
  exit 1
fi

len=${#PUSH2S3_WATCH_DIR}

# verify inotify installed
if [ ! -x "/usr/bin/inotifywait" ] ; then
    echo "ERROR: This uses the inotifywait program, which on a Debian-based system is"
    echo "part of the 'inotify-tools' package. Please install that and try again."
    exit 1
fi

# verify we have a binary for vault
if [ ! -x "$(which vault)" ]; then
  echo "ERROR: unable to find a binary for 'vault'!"
  exit 1
fi

# create PID file
#echo $$ > $PID_FILE

function acquire_aws_creds() {
  local vault_token="$(vault write "$VAULT_ROLE_LOGIN_PATH" -format=json role_id="$VAULT_ROLE_ID" secret_id="$VAULT_ROLE_SECRET_ID" | jq -r '.auth.client_token')"
  local vault_s3_access_token_kv_output="$(VAULT_TOKEN="$vault_token" vault kv get -format=json "$VAULT_KV_ACCESS_TOKEN_PATH")"
  local aws_access_key_id="$(echo "$vault_s3_access_token_kv_output" | jq -r '.data.data.aws_access_key_id')"
  local aws_secret_access_key="$(echo "$vault_s3_access_token_kv_output" | jq -r '.data.data.aws_secret_access_key')"
  local aws_session_token="$(echo "$vault_s3_access_token_kv_output" | jq -r '.data.data.aws_session_token')"

  export AWS_ACCESS_KEY_ID="$aws_access_key_id"
  export AWS_SECRET_ACCESS_KEY="$aws_secret_access_key"
  export AWS_SESSION_TOKEN="$aws_session_token"
}

# file upload
function upload() {
    local path=$1
    local file=$2
    local target=${path:$len}

    acquire_aws_creds

    aws s3 cp "${path}${file}" "s3://${PUSH2S3_BUCKET}${target}${file}"
}
function delete() {
    local path=$1
    local file=$2
    local target=${path:$len}

    acquire_aws_creds

    aws s3 rm "s3://${PUSH2S3_BUCKET}${target}${file}"
}

# init
inotifywait --recursive --monitor --exclude '.*\.sw[px]*$|4913|~$' $PUSH2S3_WATCH_DIR |
while read action_dir event_list action_file; do
    if [[ ${action_dir}${action_file} =~ .*/\..* ]]; then
        echo "Hidden file ignored"
    else
        #case "${event_list}" in
        #  DELETE* )
        #    echo "DELETE from s3 $action_dir$action_file"
        #    delete "$action_dir" "$action_file"
        #  ;;
        #esac

        if [ -f "$action_dir$action_file" ]; then # only process a file, not a directory
            case "${event_list}" in
              CLOSE_WRITE* )
                echo "UPLOAD to s3 $action_dir$action_file"
                upload "$action_dir" "$action_file"
              ;;
              MOVED_TO* )
                echo "UPLOAD to s3 $action_dir$action_file"
                upload "$action_dir" "$action_file"
              ;;
            esac
        fi

        #echo "Got an event $action_dir$action_file $event_list"
    fi
done
